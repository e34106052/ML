{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MusicGen 音樂生成及預測系統\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import librosa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# 設定隨機種子\n",
    "SEED = 12\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "# 載入資料與預處理\n",
    "data = pd.read_csv('data_features.csv')\n",
    "X = data.drop(['filename', 'label'], axis=1).values\n",
    "# 標準化 (使用原 notebook 相同邏輯)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音樂風格分辨器模型\n",
    "### Music Genre Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenreClassifier(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=26, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.6, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.4, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.4, inplace=False)\n",
       "    (9): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.4, inplace=False)\n",
       "    (12): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GenreClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 1024),  # 增加第一層神經元\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),              # 降低Dropout\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def extract_features_for_prediction(audio_path):\n",
    "    \"\"\"提取與訓練時相同的26維特徵，使用3秒片段\"\"\"\n",
    "    try:\n",
    "        # 載入音頻檔案\n",
    "        y, sr = librosa.load(audio_path, sr=22050)\n",
    "        \n",
    "        # 計算可以切成幾個3秒片段\n",
    "        segment_length = sr * 3  # 3秒的樣本數\n",
    "        num_segments = len(y) // segment_length\n",
    "        \n",
    "        if num_segments == 0:\n",
    "            # 如果音頻長度不足3秒，補零\n",
    "            y = np.pad(y, (0, segment_length - len(y)), 'constant')\n",
    "            num_segments = 1\n",
    "        \n",
    "        # 儲存所有片段的特徵\n",
    "        all_features = []\n",
    "        \n",
    "        # 處理每個3秒片段\n",
    "        for i in range(num_segments):\n",
    "            start = i * segment_length\n",
    "            end = start + segment_length\n",
    "            segment = y[start:end]\n",
    "            \n",
    "            features = []\n",
    "            \n",
    "            # 1. chroma_stft\n",
    "            chroma_stft = librosa.feature.chroma_stft(y=segment, sr=sr)\n",
    "            features.append(np.mean(chroma_stft))\n",
    "            \n",
    "            # 2. rmse (使用 rms)\n",
    "            rms = librosa.feature.rms(y=segment)\n",
    "            features.append(np.mean(rms))\n",
    "            \n",
    "            # 3. spectral_centroid\n",
    "            spectral_centroid = librosa.feature.spectral_centroid(y=segment, sr=sr)\n",
    "            features.append(np.mean(spectral_centroid))\n",
    "            \n",
    "            # 4. spectral_bandwidth\n",
    "            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=segment, sr=sr)\n",
    "            features.append(np.mean(spectral_bandwidth))\n",
    "            \n",
    "            # 5. rolloff\n",
    "            rolloff = librosa.feature.spectral_rolloff(y=segment, sr=sr)\n",
    "            features.append(np.mean(rolloff))\n",
    "            \n",
    "            # 6. zero_crossing_rate\n",
    "            zcr = librosa.feature.zero_crossing_rate(segment)\n",
    "            features.append(np.mean(zcr))\n",
    "            \n",
    "            # 7-26. mfcc1 到 mfcc20\n",
    "            mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=20)\n",
    "            for j in range(20):\n",
    "                features.append(np.mean(mfcc[j]))\n",
    "            \n",
    "            all_features.append(features)\n",
    "        \n",
    "        # 計算所有片段特徵的平均值\n",
    "        mean_features = np.mean(all_features, axis=0)\n",
    "        return mean_features.reshape(1, -1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"特徵提取失敗: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_music_genre(audio_path, model, scaler):\n",
    "    \"\"\"預測音樂風格\"\"\"\n",
    "    \n",
    "    # 音樂類型標籤 (與訓練時相同順序)\n",
    "    genres = ['blues', 'classical', 'country', 'disco', 'hiphop', \n",
    "              'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "    \n",
    "    # 提取特徵\n",
    "    features = extract_features_for_prediction(audio_path)\n",
    "    \n",
    "    if features is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    # 標準化特徵 (使用訓練時的 scaler)\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # 轉換為 PyTorch tensor\n",
    "    features_tensor = torch.tensor(features_scaled, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # 預測\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(features_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        confidence = probabilities[0, predicted_class].item()\n",
    "    \n",
    "    predicted_genre = genres[predicted_class]\n",
    "    all_probabilities = probabilities[0].cpu().numpy()\n",
    "    \n",
    "    return predicted_genre, confidence, all_probabilities\n",
    "\n",
    "# 載入最佳模型\n",
    "# 初始化模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GenreClassifier(input_size=X.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入MusicGen\n",
    "### Load MusicGen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Config of the audio_encoder: <class 'transformers.models.encodec.modeling_encodec.EncodecModel'> is overwritten by shared audio_encoder config: EncodecConfig {\n",
      "  \"architectures\": [\n",
      "    \"EncodecModel\"\n",
      "  ],\n",
      "  \"audio_channels\": 1,\n",
      "  \"chunk_length_s\": null,\n",
      "  \"codebook_dim\": 128,\n",
      "  \"codebook_size\": 2048,\n",
      "  \"compress\": 2,\n",
      "  \"dilation_growth_rate\": 2,\n",
      "  \"hidden_size\": 128,\n",
      "  \"kernel_size\": 7,\n",
      "  \"last_kernel_size\": 7,\n",
      "  \"model_type\": \"encodec\",\n",
      "  \"norm_type\": \"weight_norm\",\n",
      "  \"normalize\": false,\n",
      "  \"num_filters\": 64,\n",
      "  \"num_lstm_layers\": 2,\n",
      "  \"num_residual_layers\": 1,\n",
      "  \"overlap\": null,\n",
      "  \"pad_mode\": \"reflect\",\n",
      "  \"residual_kernel_size\": 3,\n",
      "  \"sampling_rate\": 32000,\n",
      "  \"target_bandwidths\": [\n",
      "    2.2\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"trim_right_ratio\": 1.0,\n",
      "  \"upsampling_ratios\": [\n",
      "    8,\n",
      "    5,\n",
      "    4,\n",
      "    4\n",
      "  ],\n",
      "  \"use_causal_conv\": false,\n",
      "  \"use_conv_shortcut\": false\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.musicgen.modeling_musicgen.MusicgenForCausalLM'> is overwritten by shared decoder config: MusicgenDecoderConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"audio_channels\": 1,\n",
      "  \"bos_token_id\": 2048,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_factor\": 0.02,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"musicgen_decoder\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codebooks\": 4,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 2048,\n",
      "  \"scale_embedding\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2048\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MusicGen 模型載入成功\n",
      "模型類型: <class '__main__.GenreClassifier'>\n",
      "處理器類型: <class 'transformers.models.musicgen.processing_musicgen.MusicgenProcessor'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "import scipy.io.wavfile\n",
    "\n",
    "# 載入模型和處理器\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
    "musicgen = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
    "print(\"✓ MusicGen 模型載入成功\")\n",
    "print(f\"模型類型: {type(model)}\")\n",
    "print(f\"處理器類型: {type(processor)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 字典 (未完成!)\n",
    "MusicGen接收使用者的prompt生成音樂，需使用合適的prompt才可生成指定風格(紀錄在style_test，名稱後有括號的代表預測的風格錯誤，需要修改prompt)，相同prompt容易生成一樣的音樂，需要更多不同prompt但能生成相同風格\n",
    "### Prompt Dictionary (Unfinished!)\n",
    "MusicGen generates music based on user prompts. To create music in a specific style, appropriate prompts are required. (Recorded in style_test; names with parentheses indicate incorrectly predicted styles, meaning the prompt needs modification.) The same prompt tends to generate similar music, so more varied prompts are needed to produce the same style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jazz standard with tenor saxophone lead, piano comping, walking upright bass, swing drum pattern, sophisticated chord changes, improvisational feel, 130 BPM, F major'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_optimized_prompts():\n",
    "    \"\"\"生成針對你的分類器優化的 prompt\"\"\"\n",
    "    optimized_prompts = {\n",
    "        'blues': \"\"\"Traditional 12-bar blues with electric guitar string bending, \n",
    "           harmonica wailing, slow shuffle rhythm 65 BPM, minor pentatonic scale,\n",
    "           NOT reggae off-beat, NOT Caribbean style, Delta blues tradition,\n",
    "           melancholic and soulful, vintage tube amplifier tone\"\"\",\n",
    "        \n",
    "        'classical': \"Classical string quartet, violin melody with cello bass line, piano accompaniment, baroque counterpoint style, concert hall reverb, elegant and refined, moderate tempo 100 BPM, D major key\",\n",
    "        \n",
    "        'country': \"\"\"Country ballad with acoustic guitar fingerpicking, pedal steel guitar slides,\n",
    "            fiddle melody, storytelling vocal style, 3/4 waltz time signature,\n",
    "            90 BPM, G major key, rural American atmosphere,\n",
    "            NO electronic beats, NO distorted guitars, NO urban elements,\n",
    "            Nashville production style, nostalgic and heartfelt\"\"\",\n",
    "        \n",
    "        'disco': \"\"\"1970s disco with four-on-the-floor kick drum, orchestral string sections,\n",
    "          syncopated bass guitar slap technique, brass stabs on beats 2 and 4,\n",
    "          125 BPM dance tempo, Bb major key, Studio 54 atmosphere,\n",
    "          NO hip-hop production, NO reggae off-beat, NO metal distortion,\n",
    "          Saturday Night Fever era sound\"\"\",\n",
    "        \n",
    "        'hiphop': \"\"\"Modern hip-hop with 808 kick drum, trap-influenced hi-hat rolls, \n",
    "            sub-bass frequencies, minimal harmonic content, 85 BPM tempo,\n",
    "            NOT disco strings, NOT four-on-the-floor pattern,\n",
    "            urban street atmosphere, quantized rhythm programming\"\"\",\n",
    "        \n",
    "        'jazz': \"Jazz standard with tenor saxophone lead, piano comping, walking upright bass, swing drum pattern, sophisticated chord changes, improvisational feel, 130 BPM, F major\",\n",
    "        \n",
    "        'metal': \"Heavy metal with palm-muted electric guitars, power chord progressions, double bass drum, aggressive and intense, fast tempo 150 BPM, E minor, high-gain distortion\",\n",
    "        \n",
    "        'pop': \"Contemporary pop with synthesizer lead melody, clean electric guitar arpeggios, steady four-four drum beat, bright and commercial production, 110 BPM, C major key\",\n",
    "        \n",
    "        'reggae': \"Classic reggae with off-beat guitar skank, bass emphasis on beats 1 and 3, one-drop drum pattern, relaxed tempo 75 BPM, Caribbean style, A minor key\",\n",
    "        \n",
    "        'rock': \"\"\"Classic rock anthem with clean electric guitar power chords, live drum kit,\n",
    "            driving eighth-note rhythm, stadium atmosphere, 135 BPM, A major key,\n",
    "            NO hip-hop beats, NO electronic elements, NO palm muting,\n",
    "            vintage Marshall amplifier tone, energetic and uplifting\"\"\"\n",
    "    }\n",
    "    \n",
    "    return optimized_prompts\n",
    "prompt = generate_optimized_prompts()\n",
    "prompt['jazz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "音樂風格編號對照表：\n",
      " 1.      blues\n",
      " 2.  classical\n",
      " 3.    country\n",
      " 4.      disco\n",
      " 5.     hiphop\n",
      " 6.       jazz\n",
      " 7.      metal\n",
      " 8.        pop\n",
      " 9.     reggae\n",
      "10.       rock\n"
     ]
    }
   ],
   "source": [
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', \n",
    "          'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "genre_dict = {i+1: genre for i, genre in enumerate(genres)}\n",
    "\n",
    "print(\"音樂風格編號對照表：\")\n",
    "for num, genre in genre_dict.items():\n",
    "    print(f\"{num:2d}. {genre:>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成音樂與預測風格系統\n",
    "根據編號選擇生成的風格，並由分辨器預測風格是否正確(duration_tokens=1503 為30秒,生成約5-10分鐘,可改成更短測試)\n",
    "### Music Generation and Style Prediction System\n",
    "Select the desired generation style by its ID, and the discriminator will predict whether the generated style is correct. (A duration_tokens value of 1503 corresponds to 30 seconds; generation typically takes 5-10 minutes, but can be shortened for testing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_predict(prompt, filename, duration_tokens=1503):\n",
    "    \"\"\"生成音樂並進行風格預測\"\"\"\n",
    "    # 獲取當前時間並格式化\n",
    "    from datetime import datetime\n",
    "    current_time = datetime.now().strftime(\"%H%M\")\n",
    "    \n",
    "    # 在檔案名稱中加入時間戳記\n",
    "    filename_with_time = f\"{filename.rsplit('.', 1)[0]}_{current_time}.wav\"\n",
    "    \n",
    "    # 生成音樂\n",
    "    inputs = processor(\n",
    "        text=[prompt],\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    \n",
    "    audio_values = musicgen.generate(**inputs, max_new_tokens=duration_tokens)\n",
    "    sampling_rate = musicgen.config.audio_encoder.sampling_rate\n",
    "    \n",
    "    # 保存檔案\n",
    "    scipy.io.wavfile.write(filename_with_time, \n",
    "                          rate=sampling_rate, \n",
    "                          data=audio_values[0, 0].numpy())\n",
    "    print(f\"已保存: {filename_with_time}\")\n",
    "    \n",
    "    # 進行風格預測\n",
    "    predicted_genre, confidence, all_probs = predict_music_genre(filename_with_time, model, scaler)\n",
    "    \n",
    "    if predicted_genre is not None:\n",
    "        print(\"\\n=== 音樂風格預測結果 ===\")\n",
    "        print(f\"預測風格: {predicted_genre}\")\n",
    "        print(f\"信心度: {confidence:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        print(\"所有風格的機率分布:\")\n",
    "        for i, (genre, prob) in enumerate(zip(genres, all_probs)):\n",
    "            print(f\"  {genre:>10}: {prob:.4f} ({'█' * int(prob * 20)})\")\n",
    "        \n",
    "        # 顯示前3名預測結果\n",
    "        top_3_indices = all_probs.argsort()[-3:][::-1]\n",
    "        print(f\"\\n前3名預測結果:\")\n",
    "        for i, idx in enumerate(top_3_indices):\n",
    "            print(f\"  {i+1}. {genres[idx]:>10}: {all_probs[idx]:.4f}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"預測失敗，請檢查音檔路徑和格式\")\n",
    "\n",
    "# 使用範例\n",
    "folder_path = 'music'\n",
    "music_style = 4\n",
    "file_name = genre_dict[music_style]  # 選擇第二個風格\n",
    "audio_path = f'{folder_path}/{file_name}.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 453 753 1503\n"
     ]
    }
   ],
   "source": [
    "duration_dict = {\n",
    "    'test' : 151,    # 測試用\n",
    "    'short': 453,    # 9秒 × 50 = 450 tokens\n",
    "    'medium': 753,   # 15秒 × 50 = 750 tokens\n",
    "    'long': 1503     # 30秒 × 50 = 1500 tokens\n",
    "}\n",
    "t, s , m , l = duration_dict.values()\n",
    "print(t,s,m,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存: music/disco_2100.wav\n",
      "\n",
      "=== 音樂風格預測結果 ===\n",
      "預測風格: hiphop\n",
      "信心度: 0.8305\n",
      "\n",
      "所有風格的機率分布:\n",
      "       blues: 0.0000 ()\n",
      "   classical: 0.0000 ()\n",
      "     country: 0.0000 ()\n",
      "       disco: 0.0747 (█)\n",
      "      hiphop: 0.8305 (████████████████)\n",
      "        jazz: 0.0000 ()\n",
      "       metal: 0.0002 ()\n",
      "         pop: 0.0001 ()\n",
      "      reggae: 0.0945 (█)\n",
      "        rock: 0.0000 ()\n",
      "\n",
      "前3名預測結果:\n",
      "  1.     hiphop: 0.8305\n",
      "  2.     reggae: 0.0945\n",
      "  3.      disco: 0.0747\n"
     ]
    }
   ],
   "source": [
    "generate_and_predict(prompt[file_name], audio_path, duration_tokens=l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 音樂風格預測系統\n",
    "單純用來預測指定音樂的風格\n",
    "### Music Genre Prediction System\n",
    "This system is solely for predicting the genre of a specified piece of music."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classical, hiphop, raggae, metal, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 音樂風格預測結果 ===\n",
      "預測風格: country\n",
      "信心度: 0.8971\n",
      "\n",
      "所有風格的機率分布:\n",
      "       blues: 0.0036 ()\n",
      "   classical: 0.0001 ()\n",
      "     country: 0.8971 (█████████████████)\n",
      "       disco: 0.0010 ()\n",
      "      hiphop: 0.0010 ()\n",
      "        jazz: 0.0002 ()\n",
      "       metal: 0.0001 ()\n",
      "         pop: 0.0002 ()\n",
      "      reggae: 0.0961 (█)\n",
      "        rock: 0.0008 ()\n",
      "\n",
      "前3名預測結果:\n",
      "  1.    country: 0.8971\n",
      "  2.     reggae: 0.0961\n",
      "  3.      blues: 0.0036\n"
     ]
    }
   ],
   "source": [
    "# 進行預測\n",
    "test_audio_path = r'style_test\\country.wav'\n",
    "predicted_genre, confidence, all_probs = predict_music_genre(test_audio_path, model, scaler)\n",
    "\n",
    "if predicted_genre is not None:\n",
    "    print(\"=== 音樂風格預測結果 ===\")\n",
    "    print(f\"預測風格: {predicted_genre}\")\n",
    "    print(f\"信心度: {confidence:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"所有風格的機率分布:\")\n",
    "    for i, (genre, prob) in enumerate(zip(genres, all_probs)):\n",
    "        print(f\"  {genre:>10}: {prob:.4f} ({'█' * int(prob * 20)})\")\n",
    "    \n",
    "    # 顯示前3名預測結果\n",
    "    top_3_indices = all_probs.argsort()[-3:][::-1]\n",
    "    print(f\"\\n前3名預測結果:\")\n",
    "    for i, idx in enumerate(top_3_indices):\n",
    "        print(f\"  {i+1}. {genres[idx]:>10}: {all_probs[idx]:.4f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"預測失敗，請檢查音檔路徑和格式\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
